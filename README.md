# âœ… YouTube Transcript RAG â€” README + Architecture Diagram + Flowchart

A clean, professional, copy-ready document containing only:

* âœ… Full README
* âœ… Architecture Diagram (Mermaid)
* âœ… Flowchart (Mermaid)

---

# ðŸ“˜ **README â€” YouTube Transcript RAG (LangChain + FAISS + OpenAI)**

## ðŸ“Œ **Overview**

This project builds a **Retrieval-Augmented Generation (RAG)** pipeline that answers questions *strictly* using the transcript of any YouTube video. It retrieves the transcript, chunks it, embeds using OpenAI embeddings, indexes with FAISS, retrieves relevant chunks, and generates grounded answers with ChatOpenAI.

---

## ðŸš€ **Features**

âœ… Fetch YouTube transcript automatically
âœ… Smart text chunking with overlap
âœ… Fast vector search using FAISS
âœ… Strict grounding (LLM answers only from transcript context)
âœ… No hallucination â€” model says *"I don't know"* if context missing
âœ… Clean and modular LangChain pipeline using runnables

---

## ðŸ§© **Tech Stack**

* **LangChain** (runnables, retriever, prompt templates)
* **OpenAI** (embeddings + chat model)
* **FAISS CPU** (vector index)
* **YouTube Transcript API**
* **Python-dotenv**

---

## ðŸ”§ **Installation**

```bash
pip install -q youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv
```

---

## ðŸ” **Environment Setup**

Create a `.env` file:

```
OPENAI_API_KEY=your_openai_api_key_here
```

Then load it:

```python
from dotenv import load_dotenv
load_dotenv()
```

---

## ðŸ§  **RAG Pipeline Steps**

1. **Fetch transcript** using `YouTubeTranscriptApi`.
2. **Flatten** transcript text.
3. **Split** text into overlapping chunks.
4. **Embed chunks** using OpenAI embeddings.
5. **Index embeddings** in FAISS.
6. **Retrieve** relevant chunks for a user question.
7. **Inject** {context} + {question} into PromptTemplate.
8. **Generate grounded answer** using ChatOpenAI.
9. **Parse output** into clean string.

---

# ðŸ—ï¸ **Architecture Diagram**

```mermaid
flowchart LR
  A[YouTube Video ID] --> B[YouTubeTranscriptApi]
  B -->|Transcript Chunks| C[Flatten Transcript]
  C --> D[Recursive Text Splitter]
  D -->|Chunked Docs| E[OpenAI Embeddings]
  E -->|Vectors| F[FAISS Vector Index]

  G[User Question] --> H[Retriever (FAISS Similarity Search)]
  F --> H

  H --> I[format_docs() â†’ Combined Context]
  I --> J[PromptTemplate]
  G --> J

  J --> K[ChatOpenAI]
  K --> L[StrOutputParser]
  L --> M[Final Answer]
```

---

# ðŸ”„ **Flowchart (End-to-End Workflow)**

```mermaid
flowchart TD
  Q[User Question] --> P1[parallel_chain]

  P1 -->|retriever| CT[Retrieve Top-k Transcript Chunks]
  CT --> FD[format_docs â†’ Context Text]

  P1 -->|Passthrough| QQ[Original Question]

  FD --> PT[PromptTemplate]
  QQ --> PT

  PT --> LLM[ChatOpenAI]
  LLM --> PARSE[StrOutputParser]
  PARSE --> OUT[Final Answer Returned]
```

---

# âœ… **Ready to Use**

This document is now ready for:

* âœ… GitHub README
* âœ… Viva / Internship Presentation
* âœ… Project submission
* âœ… Portfolio showcase

Agar chaho to isme:
âœ… Full code section bhi add kar doon,
âœ… Diagrams ko PNG me export kar doon,
âœ… Dark theme version bana doon.

Bas bol dena! ðŸ”¥
