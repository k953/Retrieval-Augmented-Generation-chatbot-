Retrieval-Augmented-Generation (RAG) Chatbot

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) based chatbot using LangChain.
RAG allows Large Language Models (LLMs) to answer queries with up-to-date and domain-specific knowledge by retrieving relevant documents from a knowledge base before generating a response.


ğŸ“Œ Features

âœ… Uses LangChain for RAG pipeline

âœ… Integration with Vector Database (FAISS / Chroma can be used)

âœ… Document ingestion and embeddings creation

âœ… Context-aware answers by combining retrieval + LLM generation

âœ… Example notebook included: Rag_using_langchain.ipynb



âš™ï¸ Installation

Clone this repository and navigate into it:

git clone https://github.com/k953/Retrieval-Augmented-Generation-chatbot.git
cd Retrieval-Augmented-Generation-chatbot


Create a virtual environment (recommended):

python3 -m venv rag_env
source rag_env/bin/activate   # For Linux/Mac
rag_env\Scripts\activate      # For Windows

Install required dependencies:

pip install -r requirements.txt


(You can generate requirements.txt from the notebook by exporting installed packages if needed.)

ğŸš€ Usage

Open the Jupyter Notebook:
jupyter notebook Rag_using_langchain.ipynb
Inside the notebook, follow these steps:

Import Libraries â€“ Load LangChain, vector database, and embedding model.

Load Documents â€“ Add your custom documents (PDFs, text, or knowledge base).

Create Embeddings â€“ Convert text into embeddings using OpenAI or HuggingFace models.

Store in Vector DB â€“ Store embeddings in FAISS/Chroma for similarity search.

Build RAG Chain â€“ Combine retriever with LLM (OpenAI, Llama2, etc.).

Chat â€“ Ask queries and get contextual answers.


ğŸ“‚ Project Structure
Retrieval-Augmented-Generation-chatbot/
â”‚â”€â”€ Rag_using_langchain.ipynb   # Main RAG chatbot notebook
â”‚â”€â”€ requirements.txt            # Dependencies (to be added)
â”‚â”€â”€ README.md                   # Project documentation

ğŸ”‘ API Keys

This project requires an LLM API key (e.g., OpenAI key).
Set your key in environment variables before running the notebook:

export OPENAI_API_KEY="your_api_key_here"


For Windows (PowerShell):

setx OPENAI_API_KEY "your_api_key_here"

ğŸ“– References

LangChain Documentation

RAG Overview by OpenAI

ğŸ“Œ Future Work

Add Streamlit/Gradio interface for live chatbot

Support multiple vector databases (Weaviate, Pinecone, etc.)

Deploy as API using FastAPI






